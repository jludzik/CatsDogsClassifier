{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d1e1db",
   "metadata": {},
   "source": [
    "# Projekt Klasyfikacji Obrazów: Klasyfikator Psów i Kotów\n",
    "\n",
    "## 1. Opis Projektu\n",
    "Ten projekt koncentruje się na budowaniu i optymalizacji konwolucyjnej sieci neuronowej (CNN) do klasyfikacji obrazów psów i kotów. Głównym celem jest osiągnięcie wysokiej dokładności przy jednoczesnym eksplorowaniu technik kompresji modelu, takich jak przycinanie (pruning) i kwantyzacja, w celu zmniejszenia rozmiaru modelu i poprawy szybkości wnioskowania.\n",
    "\n",
    "## 2. Zestaw Danych\n",
    "Użyty zestaw danych to 'Dogs vs. Cats', składający się z obrazów psów i kotów. Zazwyczaj jest on zorganizowany z oddzielnymi katalogami dla każdej klasy.\n",
    "\n",
    "## 3. Konfiguracja i Instalacja\n",
    "Aby uruchomić ten projekt, będziesz potrzebować następujących bibliotek:\n",
    "- `torch`\n",
    "- `torchvision`\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `matplotlib`\n",
    "- `seaborn`\n",
    "- `scikit-learn`\n",
    "- `zipfile`\n",
    "\n",
    "```bash\n",
    "pip install torch torchvision numpy pandas matplotlib seaborn scikit-learn\n",
    "```\n",
    "\n",
    "## 4. Przetwarzanie Wstępne Danych\n",
    "Obrazy są ładowane za pomocą `torchvision.datasets.ImageFolder`. Techniki augmentacji danych są stosowane do zbioru treningowego w celu poprawy uogólniania modelu. Należą do nich:\n",
    "- Zmiana rozmiaru i losowe kadrowanie\n",
    "- Losowe odbicia poziome\n",
    "- Modyfikacja jasności, kontrastu, nasycenia i odcienia (color jittering)\n",
    "- Losowe obroty\n",
    "- Rozmycie Gaussa\n",
    "- Szum Gaussa\n",
    "- Normalizacja\n",
    "\n",
    "Zestaw danych jest podzielony na zestawy treningowy, walidacyjny i testowy (odpowiednio 80%, 10%, 10%).\n",
    "\n",
    "## 5. Architektura Modelu\n",
    "Projekt wykorzystuje niestandardowy model CNN. Architektura jest następująca:\n",
    "- **Cechy (Features)**: Sekwencyjny blok warstw konwolucyjnych, normalizacji wsadowej (batch normalization), aktywacji ReLU i warstw max-pooling.\n",
    "  - 5 bloków, zaczynając od 3 kanałów wejściowych i zwiększając do 512 kanałów wyjściowych.\n",
    "- **Klasyfikator (Classifier)**: Warstwa adaptacyjnego uśredniania puli (adaptive average pooling), spłaszczanie (flattening), dropout i warstwa liniowa do klasyfikacji binarnej.\n",
    "\n",
    "Alternatywnie, można użyć wstępnie wytrenowanego modelu ResNet18 jako szkieletu.\n",
    "\n",
    "## 6. Trening i Ocena\n",
    "**(Szczegóły pętli treningowej i funkcji straty znalazłyby się tutaj, gdyby były dostępne)**\n",
    "Modele są oceniane za pomocą różnych metryk:\n",
    "- Dokładność (Accuracy)\n",
    "- Precyzja (Precision)\n",
    "- Czułość (Recall)\n",
    "- Wynik F1 (F1-Score)\n",
    "- AUC (Pole pod krzywą charakterystyki operacyjnej odbiornika)\n",
    "- Czas wnioskowania (ms/partia)\n",
    "- Rozmiar modelu (MB)\n",
    "- Rzadkość (Sparsity) (% wag zerowych)\n",
    "\n",
    "## 7. Techniki Kompresji Modelu\n",
    "\n",
    "### Przycinanie (Pruning)\n",
    "Niestrukturyzowane przycinanie L1 jest stosowane globalnie do warstw konwolucyjnych i liniowych w celu wprowadzenia rzadkości, zmniejszając liczbę parametrów i potencjalnie przyspieszając wnioskowanie.\n",
    "\n",
    "### Kwantyzacja (Quantization)\n",
    "Dynamiczna kwantyzacja (do `torch.qint8`) jest stosowana do warstw liniowych w celu zmniejszenia zużycia pamięci i potencjalnej poprawy szybkości wnioskowania poprzez użycie typów danych o niższej precyzji.\n",
    "\n",
    "### Model Przycięty + Skwantyzowany\n",
    "Zarówno przycinanie, jak i kwantyzacja są łączone w celu osiągnięcia maksymalnej kompresji.\n",
    "\n",
    "## 8. Wyniki i Porównanie\n",
    "Poniższa tabela podsumowuje wydajność i metryki rozmiaru różnych wariantów modelu:\n",
    "\n",
    "| Model            | Rzadkość | Rozmiar (Standardowy MB) | Rozmiar (Skompresowany MB) | Dokładność (%) | Wynik F1 (%) | Średni czas wnioskowania (ms/partia) |\n",
    "|:-----------------|:---------|:-------------------|:---------------------|:-------------|:-------------|:------------------------------|\n",
    "| Oryginalny       | 0.0      | 18.03              | 16.66                | 94.28        | 94.42        | 3310.46                       |\n",
    "| Przycięty        | 49.94    | 18.03              | 9.84                 | 94.24        | 94.30        | 3281.89                       |\n",
    "| Skwantyzowany    | 0.0      | 18.03              | 16.66                | 94.24        | 94.38        | 3262.53                       |\n",
    "| Przycięty+Skwantyzowany | 49.94    | 18.03              | 9.84                 | 94.20        | 94.26        | 3296.59                       |\n",
    "\n",
    "*   **Najlepszy model dla**:\n",
    "    *   **Najmniejszy rozmiar**: `Przycięty+Skwantyzowany` (9.84 MB)\n",
    "    *   **Najwyższa dokładność**: `Oryginalny` (94.28%)\n",
    "    *   **Najszybsza prędkość**: `Skwantyzowany` (3263 ms/partia)\n",
    "    *   **Najlepsza efektywność (dokładność/rozmiar)**: `Przycięty`\n",
    "\n",
    "Wyniki te wskazują, że przycinanie i kwantyzacja skutecznie zmniejszają rozmiar modelu przy minimalnym wpływie na dokładność, a także oferują niewielkie poprawy w szybkości wnioskowania dla niektórych konfiguracji. Model `Przycięty+Skwantyzowany` osiągnął najmniejszy rozmiar, co czyni go idealnym do środowisk o ograniczonych zasobach, z niewielkim spadkiem dokładności.\n",
    "\n",
    "![Results](results.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
